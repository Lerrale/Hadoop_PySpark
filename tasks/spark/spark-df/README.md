
Часть 1 (2 балла)

Напишите запрос, который вычисляет самые популярные рестораны по количеству негативных отзывов. Для каждого города необходимо топ-10 ресторанов по количеству негативных отзывов. Отзыв считается негативным, если оценка меньше 3.

Пример аргументов:
./run.sh <output_folder>
Выходные поля:

business_id - id ресторана
city - название города
negative_cnt - количество негативных отзывов
Формат вывода (для этого бизнеса выводится результат):
8g_iMtfSiwikVnbP2etR0A\tNew York\t100500
P.S. Вы могли заметить, что задача похожа на задачу в Hive. Это так! Нам необходимо понять, что Spark SQL позволяет реализовать запросы в виде SQL.

Часть 2 (3 балла)
В данной части задания мы выясним тенденцию посещений пользователями разных категорий ресторана.

Для этого нам понадобится 2 таблицы: checkins и business. Необходимо создать каталог общих статистик посещения бизнесов по категориям. Это можно сделать следующим образом:

Из business необходимо распарсить категории этого бизнеса.
Из таблицы checkins необходимо вытащить все данные о посещении этого бизнеса.
Наша цель - посчитать количество посещений для каждой категории за каждый месяц. При этом, если посещений бизнесов данной категории за месяц не было, то мы не добавляем эту запись в таблицу.

Пример формата вывода данных (данные могут быть нереалистичны):
2015-07\tFast Food\t2890
Сортировку осуществляем по возрастанию пары год-месяц mnth. После этого сортировка осуществляется по категории.

Данные сохраняем в текстовом формате в папке <output folder>:

./run.sh <output_folder>
Выходные поля:

mnth - месяц
category - категория бизнеса;
checkins - количество посещений.